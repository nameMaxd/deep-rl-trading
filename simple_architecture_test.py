#!/usr/bin/env python3
"""
üöÄ –ü–†–û–°–¢–û–ô –¢–ï–°–¢ –ê–†–•–ò–¢–ï–ö–¢–£–†–´
üéØ –ë–∞–∑–æ–≤—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
"""

from src.rl.env import Env
from src.rl.agent import Agent
import numpy as np
from datetime import datetime

def main():
    print("üöÄ –ü–†–û–°–¢–û–ô –¢–ï–°–¢ –ê–†–•–ò–¢–ï–ö–¢–£–†–´")
    print("üéØ –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    print("=" * 50)
    
    # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    config = {
        'episodes': 50,        # –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        'trading_period': 60,  # –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥
        'window': 30,          # –º–∞–ª–µ–Ω—å–∫–æ–µ –æ–∫–Ω–æ
        'commission': 0.0002,
        
        # –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        'embeddings': 16,
        'heads': 2,
        'layers': 1,
        'fwex': 64,
        'dropout': 0.1,
        'neurons': 64,
        'lr': 0.001,
        'epsilon': 0.8,
        'epsilon_min': 0.05,
        'epsilon_decay': 0.99,
        'gamma': 0.95,
        'memory_size': 5000,
        'batch_size': 128,
        'update_freq': 5
    }
    
    print(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏—è
    train_env = Env(
        csv_paths=["GOOG_2010-2024-06.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    oos_env = Env(
        csv_paths=["GOOG_2024-07_2025-04.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    print(f"üìä –û–∫—Ä—É–∂–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω—ã:")
    print(f"   Train: {train_env.stock.obs_space.shape}")
    print(f"   OOS: {oos_env.stock.obs_space.shape}")
    
    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
    agent_params = {k: v for k, v in config.items() 
                   if k in ['embeddings', 'heads', 'layers', 'fwex', 'dropout', 'neurons',
                           'lr', 'epsilon', 'epsilon_min', 'epsilon_decay', 'gamma',
                           'memory_size', 'batch_size', 'update_freq']}
    
    agent = Agent(obs_space=train_env.stock.obs_space, **agent_params)
    
    print(f"ü§ñ –ê–≥–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω!")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_file = "models/simple-architecture-test.log"
    model_name = "simple-architecture-test"
    
    best_median = -float('inf')
    
    print(f"\nüèÉ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {config['episodes']} —ç–ø–∏–∑–æ–¥–æ–≤...")
    
    with open(log_file, "w", encoding='utf-8') as f:
        f.write(f"Simple Architecture Test - {datetime.now()}\n")
        f.write(f"Config: {config}\n")
        f.write("=" * 80 + "\n")
    
    for episode in range(config['episodes']):
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        state = train_env.reset()
        done = False
        total_reward = 0
        
        while not done:
            action = agent.act(state)
            next_state, trade_action, reward, done = train_env.step(action)
            
            agent.remember(state, action, reward, next_state, done)
            
            if len(agent.memory) > agent.batch_size:
                agent.replay()
            
            total_reward += reward
            state = next_state
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        train_metrics = train_env.get_trading_metrics()
        
        # OOS —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤
        if episode % 10 == 0:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ 3 –ø–æ–∑–∏—Ü–∏—è—Ö
            oos_profits = []
            
            for start_pos in range(0, min(30, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 10):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º reset_fixed –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                state = oos_env.reset_fixed(start_pos)
                done = False
                
                while not done:
                    action = agent.act(state, training=False)  # –ë–ï–ó exploration
                    next_state, trade_action, reward, done = oos_env.step(action)
                    state = next_state
                
                oos_metrics = oos_env.get_trading_metrics()
                oos_profits.append(oos_metrics['total_profit_dollars'])
            
            median_oos = np.median(oos_profits) if oos_profits else 0
            mean_oos = np.mean(oos_profits) if oos_profits else 0
            consistency = (np.array(oos_profits) > 0).mean() * 100 if oos_profits else 0
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            if median_oos > best_median:
                best_median = median_oos
                agent.save(f"models/{model_name}_best")
                print(f"üíæ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–µ–¥–∏–∞–Ω–∞: ${median_oos:.0f} (—ç–ø–∏–∑–æ–¥ {episode})")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            log_entry = (
                f"Ep: {episode:3d} | Train: ${train_metrics['total_profit_dollars']:4.0f} | OOS Med: ${median_oos:4.0f}\n"
                f"    Trades: {train_metrics['num_trades']} | Win%: {train_metrics['win_rate']*100:.1f}\n"
                f"    OOS: Med ${median_oos:.0f}, Mean ${mean_oos:.0f}, Consistency {consistency:.1f}%\n"
                f"    Epsilon: {agent.epsilon:.3f} | Best: ${best_median:.0f}\n"
                f"    All OOS: {[int(p) for p in oos_profits]}\n"
                + "-" * 60
            )
            
            print(log_entry)
            
            with open(log_file, "a", encoding='utf-8') as f:
                f.write(log_entry + "\n")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    agent.save(f"models/{model_name}")
    
    print(f"\nüèÅ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üíæ –ú–æ–¥–µ–ª—å: models/{model_name}")
    print(f"üèÜ –õ—É—á—à–∞—è: models/{model_name}_best")
    print(f"üìä –õ–æ–≥: {log_file}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\nüî¨ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç...")
    final_profits = []
    
    for start_pos in range(0, min(50, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 5):
        state = oos_env.reset_fixed(start_pos)
        done = False
        
        while not done:
            action = agent.act(state, training=False)
            next_state, trade_action, reward, done = oos_env.step(action)
            state = next_state
        
        oos_metrics = oos_env.get_trading_metrics()
        final_profits.append(oos_metrics['total_profit_dollars'])
    
    final_median = np.median(final_profits)
    final_consistency = (np.array(final_profits) > 0).mean() * 100
    final_std = np.std(final_profits)
    
    print(f"üìà –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏—Ç: ${final_median:.2f}")
    print(f"   Consistency: {final_consistency:.1f}%")
    print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ${final_std:.2f}")
    print(f"   –î–∏–∞–ø–∞–∑–æ–Ω: ${min(final_profits):.0f} - ${max(final_profits):.0f}")
    
    if final_consistency > 50 and final_median > 50:
        print("‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    else:
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞...")

if __name__ == "__main__":
    main() 