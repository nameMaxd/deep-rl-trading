#!/usr/bin/env python3
"""
ü§ñ TRANSFORMER v14 –° TQDM –ü–†–û–ì–†–ï–°–°-–ë–ê–†–ê–ú–ò!
üéØ –ú–æ—â–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –∂–∏–≤—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
"""

from src.rl.env import Env
from src.rl.agent import Agent
import numpy as np
from tqdm import tqdm
import time

def main():
    print("ü§ñ TRANSFORMER v14 –° –ñ–ò–í–´–ú TQDM –ü–†–û–ì–†–ï–°–°–û–ú!")
    print("üéØ –ú–æ—â–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞!")
    print("=" * 60)
    
    # –ú–æ—â–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = {
        'episodes': 250,
        'trading_period': 120,
        'window': 50,
        'commission': 0.0002,
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        'embeddings': 64,
        'heads': 4,
        'layers': 3,
        'fwex': 256,
        'dropout': 0.1,
        'neurons': 256,
        'lr': 0.0005,
        'epsilon': 0.8,
        'epsilon_min': 0.005,
        'epsilon_decay': 0.9965,
        'gamma': 0.95,
        'memory_size': 15000,
        'batch_size': 512,
        'update_freq': 3
    }
    
    print(f"üìä TRANSFORMER –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config['episodes']} —ç–ø–∏–∑–æ–¥–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏—è
    train_env = Env(
        csv_paths=["GOOG_2010-2024-06.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    oos_env = Env(
        csv_paths=["GOOG_2024-07_2025-04.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    print(f"üìä TRANSFORMER –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    print(f"   Train: {train_env.stock.obs_space.shape}")
    print(f"   OOS: {oos_env.stock.obs_space.shape}")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ—â–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∞–≥–µ–Ω—Ç–∞
    agent = Agent(
        obs_space=train_env.stock.obs_space,
        **{k: v for k, v in config.items() 
           if k not in ['episodes', 'trading_period', 'window', 'commission']}
    )
    
    print(f"ü§ñ –ú–û–©–ù–´–ô —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∞–≥–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω:")
    print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {config['embeddings']} emb, {config['heads']} heads, {config['layers']} layers")
    print(f"   FC: {config['neurons']} -> {config['neurons']} -> 3")
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–∞–º—è—Ç—å
    print("üß† –ó–∞–ø–æ–ª–Ω—è–µ–º TRANSFORMER –ø–∞–º—è—Ç—å...")
    state = train_env.reset()
    for _ in range(1500):  # –ë–æ–ª—å—à–µ –¥–ª—è –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏
        action = np.random.randint(3)
        next_state, _, reward, done = train_env.step(action)
        agent.remember(state, action, reward, next_state, done)
        state = next_state
        if done:
            state = train_env.reset()
    
    print("üèÉ TRANSFORMER –æ–±—É—á–µ–Ω–∏–µ —Å –ñ–ò–í–´–ú –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º...")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å TQDM
    best_median = -float('inf')
    
    with tqdm(range(config['episodes']), desc="ü§ñ TRANSFORMER", 
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
        
        for episode in pbar:
            # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
            state = train_env.reset()
            done = False
            total_reward = 0
            
            while not done:
                action = agent.act(state)
                next_state, _, reward, done = train_env.step(action)
                agent.remember(state, action, reward, next_state, done)
                agent.update()
                total_reward += reward
                state = next_state
            
            train_profit = train_env.current_equity - train_env.initial_capital
            
            # OOS —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 25 —ç–ø–∏–∑–æ–¥–æ–≤
            if episode % 25 == 0:
                oos_profits = []
                for start_pos in range(0, min(50, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 10):
                    state = oos_env.reset_fixed(start_pos)
                    done = False
                    
                    while not done:
                        action = agent.act(state, training=False)
                        next_state, _, reward, done = oos_env.step(action)
                        state = next_state
                    
                    oos_profits.append(oos_env.current_equity - oos_env.initial_capital)
                
                oos_median = np.median(oos_profits)
                
                if oos_median > best_median:
                    best_median = oos_median
                    agent.save(f"models/tqdm-transformer-v14_best")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                pbar.set_postfix({
                    'Train': f'${train_profit:.0f}',
                    'OOS_Med': f'${oos_median:.0f}',
                    'Best': f'${best_median:.0f}',
                    'Œµ': f'{agent.epsilon:.3f}',
                    'Trades': f'{train_env.trade_count}'
                })
            else:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ training
                pbar.set_postfix({
                    'Train': f'${train_profit:.0f}',
                    'Œµ': f'{agent.epsilon:.3f}',
                    'Trades': f'{train_env.trade_count}'
                })
            
            time.sleep(0.03)  # –ë—ã—Å—Ç—Ä–µ–µ –¥–ª—è –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\nüî¨ TRANSFORMER —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    final_profits = []
    
    with tqdm(range(0, min(140, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 7),
              desc="üß™ TRANSFORMER —Ç–µ—Å—Ç",
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as test_bar:
        
        for start_pos in test_bar:
            state = oos_env.reset_fixed(start_pos)
            done = False
            
            while not done:
                action = agent.act(state, training=False)
                next_state, _, reward, done = oos_env.step(action)
                state = next_state
            
            profit = oos_env.current_equity - oos_env.initial_capital
            final_profits.append(profit)
            
            test_bar.set_postfix({
                'Profit': f'${profit:.0f}',
                'Avg': f'${np.mean(final_profits):.0f}'
            })
    
    # TRANSFORMER —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    median_profit = np.median(final_profits)
    mean_profit = np.mean(final_profits)
    consistency = len([p for p in final_profits if p > 0]) / len(final_profits) * 100
    
    print(f"\nü§ñ TRANSFORMER v14 –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   üí∞ –ú–µ–¥–∏–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏—Ç: ${median_profit:.2f}")
    print(f"   üìà –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ñ–∏—Ç: ${mean_profit:.2f}")  
    print(f"   üéØ Consistency: {consistency:.1f}%")
    print(f"   üèÜ –õ—É—á—à–∏–π –º–µ–¥–∏–∞–Ω–Ω—ã–π: ${best_median:.2f}")
    print(f"   üìä –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {len(final_profits)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    agent.save("models/tqdm-transformer-v14")
    print(f"üíæ TRANSFORMER –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/tqdm-transformer-v14")
    
    print("ü§ñ TRANSFORMER v14 –ó–ê–í–ï–†–®–ï–ù!")
    
    return {
        'name': 'TRANSFORMER v14',
        'median_profit': median_profit,
        'mean_profit': mean_profit,
        'consistency': consistency,
        'best_median': best_median,
        'total_tests': len(final_profits)
    }

if __name__ == "__main__":
    main() 