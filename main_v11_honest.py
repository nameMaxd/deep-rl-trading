from src.rl.agent import Agent
from src.rl.env import Env
from src.stock.stock import Stock
import numpy as np
import os


def main():
    """v11: –ß–ï–°–¢–ù–ê–Ø –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–µ–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model_name = "google-trading-v11-honest"
    
    print("üéØ –ß–ï–°–¢–ù–ê–Ø –ê–¢–ê–ö–ê: Google trading bot v11!")
    print("üî¨ –ù–û–í–ê–Ø –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø: –ß–µ—Å—Ç–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ!")
    print("üìä –ê–ù–ê–õ–ò–ó –ø—Ä–æ–±–ª–µ–º v9/v10:")
    print("   ‚ùå Cherry-picking: –±—Ä–∞–ª–∏ –ª—É—á—à–∏–π –∏–∑ 7 –ø—Ä–æ–≥–æ–Ω–æ–≤")
    print("   ‚ùå –°–ª—É—á–∞–π–Ω—ã–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏") 
    print("   ‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ OOS –¥–∞–Ω–Ω—ã—Ö")
    print("   ‚ùå –í—ã—Å–æ–∫–∏–π epsilon –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏")
    print("")
    print("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø v11:")
    print("   ‚úÖ –ß–ï–°–¢–ù–û–ï —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: 1 –ø—Ä–æ–≥–æ–Ω, —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ä—Ç")
    print("   ‚úÖ Comprehensive evaluation: –≤—Å–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏")
    print("   ‚úÖ NO OOS training: —É–±–∏—Ä–∞–µ–º —á–∏—Ç–µ—Ä—Å—Ç–≤–æ")
    print("   ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –º–µ–Ω—å—à–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏")
    print("=" * 70)
    
    # –°–¢–ê–ë–ò–õ–¨–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —á–µ—Å—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
    training_episodes = 300    # –£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    trading_period = 120      # –¢–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    window_size = 50          # –¢–æ—Ç –∂–µ window
    fee = 0.0002             # –¢–∞ –∂–µ –∫–æ–º–∏—Å—Å–∏—è
    
    # –î–∞–Ω–Ω—ã–µ
    train_csv = "GOOG_2010-2024-06.csv"
    oos_csv = "GOOG_2024-07_2025-04.csv"
    
    print(f"üìä –°–¢–ê–ë–ò–õ–¨–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã v11:")
    print(f"üìà –≠–ø–∏–∑–æ–¥—ã: {training_episodes} (—É–º–µ—Ä–µ–Ω–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)")
    print(f"‚è∞ –ü–µ—Ä–∏–æ–¥: {trading_period} –¥–Ω–µ–π")
    print(f"ü™ü –û–∫–Ω–æ: {window_size} –¥–Ω–µ–π")
    print(f"üí∞ –ö–æ–º–∏—Å—Å–∏—è: {fee*100}%")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏—è
    train_env = Env(csv_paths=[train_csv], fee=fee, trading_period=trading_period, window=window_size)
    oos_env = Env(csv_paths=[oos_csv], fee=fee, trading_period=trading_period, window=window_size)
    
    # –°–¢–ê–ë–ò–õ–¨–ù–´–ï —Ü–µ–ª–∏
    train_env.target_profit = 500     # –£–º–µ—Ä–µ–Ω–Ω–∞—è —Ü–µ–ª—å
    train_env.max_trades_per_episode = 15   # –£–º–µ—Ä–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    train_env.min_trades_per_episode = 5    # –ú–∏–Ω–∏–º—É–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    
    print(f"üìä –°–¢–ê–ë–ò–õ–¨–ù–û–ï –æ–∫—Ä—É–∂–µ–Ω–∏–µ v11:")
    print(f"   Observation space: {train_env.stock.obs_space.shape}")
    print(f"   Target profit: ${train_env.target_profit}")
    print(f"   Trading range: {train_env.min_trades_per_episode}-{train_env.max_trades_per_episode} —Å–¥–µ–ª–æ–∫")
    
    # –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è v11
    model_config = {
        'embeddings': 32,      # –£–º–µ—Ä–µ–Ω–Ω–æ - –Ω–µ –ø–µ—Ä–µ—É—Å–ª–æ–∂–Ω—è–µ–º
        'heads': 2,            # –£–º–µ—Ä–µ–Ω–Ω–æ
        'layers': 2,           # –£–º–µ—Ä–µ–Ω–Ω–æ
        'fwex': 128,          # –£–º–µ—Ä–µ–Ω–Ω–æ
        'dropout': 0.05,      # –ù–ò–ó–ö–ò–ô –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        'neurons': 128,       # –£–º–µ—Ä–µ–Ω–Ω–æ
        'lr': 0.001,          # –ù–ò–ó–ö–ò–ô –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        'epsilon': 1.0,
        'epsilon_min': 0.01,  # –û–ß–ï–ù–¨ –Ω–∏–∑–∫–∏–π –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
        'epsilon_decay': 0.997,  # –ë—ã—Å—Ç—Ä—ã–π decay –∫ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º—É
        'gamma': 0.95,        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        'memory_size': 5000,  # –£–º–µ—Ä–µ–Ω–Ω–æ
        'batch_size': 512,    # –ë–û–õ–¨–®–û–ô –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        'update_freq': 5      # –£–º–µ—Ä–µ–Ω–Ω–æ
    }
    
    print(f"====== –°–¢–ê–ë–ò–õ–¨–ù–ê–Ø –º–æ–¥–µ–ª—å v11: {model_name} ======")
    print("üîß –°–¢–ê–ë–ò–õ–¨–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —á–µ—Å—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏:")
    for key, value in model_config.items():
        print(f"  {key}: {value}")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ v11
    agent = Agent(obs_space=train_env.stock.obs_space, **model_config)
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_file = f"models/{model_name}.log"
    
    print(f"üî¨ –ß–ï–°–¢–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ v11...")
    print(f"üéØ –¶–ï–õ–¨: –°—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å –±–µ–∑ –æ–±–º–∞–Ω–∞!")
    
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ (–∫–∞–∫ –æ–±—ã—á–Ω–æ)
    print("üì¶ –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏...")
    initial_memory_size = model_config['memory_size'] // 4
    
    attempts = 0
    step_count = 0
    while len(agent.memory) < initial_memory_size and attempts < 50:
        if step_count % 100 == 0:
            state = train_env.reset()
        else:
            action = agent.act(state, training=True)
            next_state, _, reward, done = train_env.step(action)
            agent.remember(state, action, reward, next_state, done)
            state = next_state
            step_count += 1
        attempts += 1
    
    print(f"‚úÖ –ü–∞–º—è—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∞: {len(agent.memory)} –∑–∞–ø–∏—Å–µ–π")
    
    # –ß–ï–°–¢–ù–´–ô —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è v11
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥-—Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    header = "episode,train_profit,oos_profit_fixed,oos_profit_median,oos_profit_mean,oos_win_rate,oos_consistency,train_trades,oos_trades,train_win_rate,train_sharpe,oos_sharpe,loss,epsilon"
    with open(log_file, "w") as f:
        f.write(header + "\n")
    
    best_oos_median = -float('inf')
    best_model_episode = 0
    stable_results_count = 0  # –°—á—ë—Ç—á–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    # –ù–ï–¢ –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–Ø –ù–ê OOS! –£–±–∏—Ä–∞–µ–º train_on_oos_aggressively!
    
    try:
        for episode in range(training_episodes):
            # –û–±—É—á–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö
            state = train_env.reset()
            done = False
            episode_loss = 0.0
            loss_count = 0
            
            while not done:
                action = agent.act(state, training=True)
                next_state, _, reward, done = train_env.step(action)
                agent.remember(state, action, reward, next_state, done)
                
                # –û–±—É—á–µ–Ω–∏–µ
                if len(agent.memory) > model_config['batch_size']:
                    loss = agent.update()
                    if loss > 0:
                        episode_loss += loss
                        loss_count += 1
                
                state = next_state
            
            # –ú–µ—Ç—Ä–∏–∫–∏ train
            train_metrics = train_env.get_trading_metrics()
            avg_loss = episode_loss / max(loss_count, 1)
            
            # –ß–ï–°–¢–ù–û–ï OOS —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            oos_results = test_oos_comprehensive(agent, oos_env)
            
            # –ü–æ–¥—Å—á—ë—Ç —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if oos_results['median_profit'] >= 50 and oos_results['consistency'] >= 0.6:
                stable_results_count += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ –ú–ï–î–ò–ê–ù–ù–û–ú–£ –ø—Ä–æ—Ñ–∏—Ç—É
            if oos_results['median_profit'] > best_oos_median:
                best_oos_median = oos_results['median_profit']
                best_model_episode = episode
                agent.save(f"models/{model_name}_best")
                print(f"üíé –ù–æ–≤—ã–π –ª—É—á—à–∏–π –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: ${oos_results['median_profit']:.0f} (—ç–ø–∏–∑–æ–¥ {episode})")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ - –ù–ï–ú–ï–î–õ–ï–ù–ù–ê–Ø –∑–∞–ø–∏—Å—å
            log_line = f"{episode},{train_metrics['total_profit_dollars']:.2f},{oos_results['fixed_profit']:.2f},"
            log_line += f"{oos_results['median_profit']:.2f},{oos_results['mean_profit']:.2f},"
            log_line += f"{oos_results['win_rate']:.3f},{oos_results['consistency']:.3f},"
            log_line += f"{train_metrics['num_trades']},{oos_results['avg_trades']:.1f},"
            log_line += f"{train_metrics['win_rate']:.3f},{train_metrics['sharpe_ratio']:.3f},"
            log_line += f"{oos_results['sharpe']:.3f},{avg_loss:.6f},{agent.epsilon:.3f}"
            
            with open(log_file, "a") as f:
                f.write(log_line + "\n")
            
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            if episode % 50 == 0:
                print(f"üìù –õ–æ–≥ –æ–±–Ω–æ–≤–ª—ë–Ω –¥–æ —ç–ø–∏–∑–æ–¥–∞ {episode}")
            
            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏
            if episode % 100 == 0 and episode > 0:
                agent.save(f"models/{model_name}_ep{episode}")
                print(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å: ep{episode}")
            
            # –í—ã–≤–æ–¥ –∫–∞–∂–¥—ã–µ 25 —ç–ø–∏–∑–æ–¥–æ–≤
            if episode % 25 == 0:
                stability_rate = stable_results_count / (episode + 1) * 100
                print(f"Ep: {episode} | Train: ${train_metrics['total_profit_dollars']:.0f} | "
                      f"OOS Med: ${oos_results['median_profit']:.0f}")
                print(f"    Train: {train_metrics['num_trades']} trades, {train_metrics['win_rate']*100:.1f}% win")
                print(f"    OOS: Med ${oos_results['median_profit']:.0f}, Mean ${oos_results['mean_profit']:.0f}, "
                      f"Consistency {oos_results['consistency']*100:.1f}%")
                print(f"    üìä Stability rate: {stability_rate:.1f}% | Best median: ${best_oos_median:.0f}")
                print("-" * 80)
            
            # Early stopping –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            if episode >= 100:
                recent_stability = stable_results_count / episode
                if recent_stability >= 0.8:  # 80% —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    print(f"üéØ –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! Stopping at episode {episode}")
                    break
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    agent.save(f"models/{model_name}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è comprehensive –æ—Ü–µ–Ω–∫–∞
    print(f"\nüî¨ –§–ò–ù–ê–õ–¨–ù–ê–Ø –ß–ï–°–¢–ù–ê–Ø –û–¶–ï–ù–ö–ê:")
    final_oos = test_oos_comprehensive(agent, oos_env, detailed=True)
    
    print(f"\n‚úÖ –ß–ï–°–¢–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ v11 –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/{model_name}")
    print(f"üíé –õ—É—á—à–∏–π –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: models/{model_name}_best (—ç–ø–∏–∑–æ–¥ {best_model_episode})")
    print(f"üìä –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_file}")
    print(f"üéØ –°—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {stable_results_count}/{episode+1} ({stable_results_count/(episode+1)*100:.1f}%)")
    
    # –ß–µ—Å—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å–ø–µ—Ö–∞
    print(f"\nüìà –ß–ï–°–¢–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏—Ç: ${final_oos['median_profit']:.2f}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ñ–∏—Ç: ${final_oos['mean_profit']:.2f}")
    print(f"   Win rate: {final_oos['win_rate']*100:.1f}%")
    print(f"   Consistency: {final_oos['consistency']*100:.1f}%")
    print(f"   Sharpe ratio: {final_oos['sharpe']:.2f}")
    print(f"   –ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞: {final_oos['max_drawdown']*100:.1f}%")
    
    if final_oos['median_profit'] >= 50 and final_oos['consistency'] >= 0.6:
        print(f"üéâ –ß–ï–°–¢–ù–´–ô –£–°–ü–ï–•! –ú–µ–¥–∏–∞–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å!")
    elif final_oos['median_profit'] >= 20 and final_oos['consistency'] >= 0.5:
        print(f"üìà –ü–†–û–ì–†–ï–°–°! –î–≤–∏–∂–µ–º—Å—è –∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏!")
    else:
        print(f"‚ùå –ù—É–∂–Ω–æ –¥–æ—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º–æ–¥–µ–ª—å")


def test_oos_honest(agent, oos_env, start_position=0):
    """–ß–ï–°–¢–ù–û–ï —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ - –æ–¥–∏–Ω –ø—Ä–æ–≥–æ–Ω, —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∞—Ä—Ç"""
    old_epsilon = agent.epsilon
    agent.epsilon = 0  # –ü–æ–ª–Ω—ã–π –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º
    
    # –û–î–ò–ù –ø—Ä–æ–≥–æ–Ω —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å—Ç–∞—Ä—Ç–æ–º
    state = oos_env.reset_fixed(start_position=start_position)
    done = False
    
    while not done:
        action = agent.act(state, training=False)
        next_state, _, reward, done = oos_env.step(action)
        state = next_state
    
    agent.epsilon = old_epsilon
    return oos_env.get_trading_metrics()


def test_oos_comprehensive(agent, oos_env, detailed=False):
    """Comprehensive OOS —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏—è—Ö"""
    results = []
    max_starts = len(oos_env.stock.closes) - oos_env.trading_period - 10
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∫–∞–∂–¥–æ–π 5-–π –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
    step = 5 if not detailed else 3
    test_positions = list(range(0, max_starts, step))
    
    if detailed:
        print(f"üî¨ Comprehensive —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(test_positions)} –ø–æ–∑–∏—Ü–∏—è—Ö...")
    
    for i, start_pos in enumerate(test_positions):
        metrics = test_oos_honest(agent, oos_env, start_position=start_pos)
        results.append({
            'profit': metrics['total_profit_dollars'],
            'trades': metrics['num_trades'],
            'win_rate': metrics['win_rate'],
            'sharpe': metrics['sharpe_ratio'],
            'max_drawdown': metrics['max_drawdown']
        })
        
        if detailed and i % 10 == 0:
            print(f"   –ü–æ–∑–∏—Ü–∏—è {i+1}/{len(test_positions)}: ${metrics['total_profit_dollars']:.0f}")
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    profits = [r['profit'] for r in results]
    trades = [r['trades'] for r in results]
    win_rates = [r['win_rate'] for r in results]
    sharpes = [r['sharpe'] for r in results]
    drawdowns = [r['max_drawdown'] for r in results]
    
    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–ø–µ—Ä–≤–∞—è –ø–æ–∑–∏—Ü–∏—è)
    fixed_profit = profits[0] if profits else 0
    
    return {
        'fixed_profit': fixed_profit,
        'mean_profit': np.mean(profits),
        'median_profit': np.median(profits), 
        'std_profit': np.std(profits),
        'best_profit': np.max(profits),
        'worst_profit': np.min(profits),
        'win_rate': np.mean(win_rates),
        'consistency': len([p for p in profits if p > 0]) / len(profits),
        'sharpe': np.mean(sharpes),
        'max_drawdown': np.mean(drawdowns),
        'avg_trades': np.mean(trades),
        'total_tests': len(results)
    }


if __name__ == "__main__":
    main() 