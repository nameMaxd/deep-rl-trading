#!/usr/bin/env python3
"""
üß† LSTM –ê–¢–ê–ö–ê v13: –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø!
üéØ –¶–ï–õ–¨: LSTM + —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π epsilon –±–µ–∑ adaptive boost
"""

import torch
import torch.nn as nn
import numpy as np
from src.rl.env import Env
from src.rl.agent import Agent
import os
from datetime import datetime

class LSTMAgent(Agent):
    """LSTM –∞–≥–µ–Ω—Ç –±–µ–∑ –≤—Å—è–∫–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤"""
    
    def __init__(self, obs_space, **kwargs):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º LSTM-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.lstm_hidden = kwargs.pop('lstm_hidden', 128)
        self.lstm_layers = kwargs.pop('lstm_layers', 2)
        self.fc_hidden = kwargs.pop('fc_hidden', 64)
        
        # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–ª–∞—Å—Å
        super().__init__(obs_space, **kwargs)
        
    def _create_network(self):
        """–°–æ–∑–¥–∞–µ–º LSTM —Å–µ—Ç—å –≤–º–µ—Å—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞"""
        
        feature_dim = self.obs_space[1]  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
        sequence_len = self.obs_space[2]  # –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        return LSTMQNetwork(
            feature_dim=feature_dim,
            sequence_len=sequence_len,
            lstm_hidden=self.lstm_hidden,
            lstm_layers=self.lstm_layers,
            fc_hidden=self.fc_hidden,
            action_size=3,
            dropout=self.dropout
        )
    
    def act(self, state, training=True):
        """–§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ô epsilon decay –ë–ï–ó adaptive boost!"""
        if training and np.random.random() <= self.epsilon:
            action = np.random.choice(3)
            if self.steps % 1000 == 0:
                print(f"üé≤ Random action: {action}, epsilon: {self.epsilon:.3f}")
            return action
        
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å
        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
        q_values = self.q_network(state_tensor)
        action = q_values.cpu().data.numpy().argmax()
        
        if self.steps % 1000 == 0:
            print(f"üß† Neural action: {action}, Q: {q_values.cpu().data.numpy()}")
        
        return action
    
    def step(self, state, action, reward, next_state, done):
        """–®–∞–≥ LSTM –∞–≥–µ–Ω—Ç–∞ —Å –ü–†–ê–í–ò–õ–¨–ù–´–ú epsilon decay"""
        self.memory.add(state, action, reward, next_state, done)
        self.steps += 1
        
        # –ü–†–û–°–¢–û–ô epsilon decay –ë–ï–ó adaptive boost
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
            if self.steps % 1000 == 0:
                print(f"üìâ Epsilon decay: {self.epsilon:.3f}")
        
        if len(self.memory) > self.batch_size and self.steps % self.update_freq == 0:
            experiences = self.memory.sample()
            self.learn(experiences)


class LSTMQNetwork(nn.Module):
    """–ü—Ä–æ—Å—Ç–∞—è LSTM Q-—Å–µ—Ç—å"""
    
    def __init__(self, feature_dim, sequence_len, lstm_hidden, lstm_layers, fc_hidden, action_size, dropout=0.1):
        super().__init__()
        
        self.feature_dim = feature_dim
        self.sequence_len = sequence_len
        self.lstm_hidden = lstm_hidden
        self.lstm_layers = lstm_layers
        
        # Input embedding (optional)
        self.input_norm = nn.LayerNorm(feature_dim)
        
        # LSTM layers
        self.lstm = nn.LSTM(
            input_size=feature_dim,
            hidden_size=lstm_hidden,
            num_layers=lstm_layers,
            batch_first=True,
            dropout=dropout if lstm_layers > 1 else 0.0,
            bidirectional=False
        )
        
        # FC layers
        self.fc1 = nn.Linear(lstm_hidden, fc_hidden)
        self.dropout = nn.Dropout(dropout)
        self.fc2 = nn.Linear(fc_hidden, fc_hidden // 2)
        self.fc_out = nn.Linear(fc_hidden // 2, action_size)
        
        self.activation = nn.ReLU()
        
    def forward(self, x):
        # x: (batch, timesteps, features)
        batch_size = x.size(0)
        
        # Normalize input
        x = self.input_norm(x)
        
        # LSTM forward
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # Take last output
        last_output = lstm_out[:, -1, :]  # (batch, lstm_hidden)
        
        # FC layers
        x = self.activation(self.fc1(last_output))
        x = self.dropout(x)
        x = self.activation(self.fc2(x))
        q_values = self.fc_out(x)
        
        return q_values


def main():
    """LSTM —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç v13 –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô"""
    
    print("üß† LSTM –ê–¢–ê–ö–ê v13: –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø!")
    print("üéØ –¶–ï–õ–¨: LSTM + —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π epsilon + –°–¢–ê–ù–î–ê–†–¢–ù–´–ï —Ñ–∏—á–∏")
    print("üîß –ë–ï–ó adaptive epsilon boost!")
    print("=" * 60)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã LSTM —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    config = {
        'episodes': 200,
        'trading_period': 90,  # —Å—Ä–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥
        'window': 40,          # —á—É—Ç—å –±–æ–ª—å—à–µ –æ–∫–Ω–æ
        'target_profit': 500,  # —É–º–µ—Ä–µ–Ω–Ω–∞—è —Ü–µ–ª—å
        'commission': 0.0002,
        
        # LSTM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        'lstm_hidden': 128,
        'lstm_layers': 2,
        'fc_hidden': 64,
        'dropout': 0.1,
        
        # –û–±—É—á–µ–Ω–∏–µ
        'lr': 0.001,
        'epsilon': 0.9,        # —Å—Ç–∞—Ä—Ç—É–µ–º –≤—ã—Å–æ–∫–æ
        'epsilon_min': 0.01,   # –Ω–æ –æ–ø—É—Å–∫–∞–µ–º –Ω–∏–∑–∫–æ
        'epsilon_decay': 0.995, # –º–µ–¥–ª–µ–Ω–Ω—ã–π decay
        'gamma': 0.95,
        'memory_size': 10000,
        'batch_size': 256,
        'update_freq': 5
    }
    
    print(f"üìä LSTM –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ –°–¢–ê–ù–î–ê–†–¢–ù–û
    train_env = Env(
        csv_paths=["GOOG_2010-2024-06.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    oos_env = Env(
        csv_paths=["GOOG_2024-07_2025-04.csv"],
        fee=config['commission'],
        trading_period=config['trading_period'],
        window=config['window']
    )
    
    print(f"üìä LSTM –æ–∫—Ä—É–∂–µ–Ω–∏–µ:")
    print(f"   Train observation space: {train_env.stock.obs_space.shape}")
    print(f"   OOS observation space: {oos_env.stock.obs_space.shape}")
    print(f"   Target profit: ${config['target_profit']}")
    
    # –°–æ–∑–¥–∞–µ–º LSTM –∞–≥–µ–Ω—Ç–∞ - –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–æ–º–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è env
    agent_params = {k: v for k, v in config.items() 
                   if k not in ['episodes', 'trading_period', 'window', 'target_profit', 'commission']}
    
    agent = LSTMAgent(
        obs_space=train_env.stock.obs_space,
        **agent_params
    )
    
    print(f"üß† LSTM –∞–≥–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω:")
    print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: LSTM({config['lstm_hidden']}) x {config['lstm_layers']}")
    print(f"   FC: {config['fc_hidden']} -> {config['fc_hidden']//2} -> 3")
    print(f"   Epsilon: {config['epsilon']} -> {config['epsilon_min']} (decay: {config['epsilon_decay']})")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_file = f"models/google-trading-v13-lstm.log"
    model_name = "google-trading-v13-lstm"
    
    best_median = -float('inf')
    stability_count = 0
    
    print(f"\nüß† –ù–∞—á–∏–Ω–∞—é LSTM –æ–±—É—á–µ–Ω–∏–µ...")
    
    with open(log_file, "w", encoding='utf-8') as f:
        f.write(f"üß† LSTM Training Log v13 - {datetime.now()}\n")
        f.write(f"Config: {config}\n")
        f.write("=" * 80 + "\n")
    
    for episode in range(config['episodes']):
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        train_env.reset()
        total_reward = 0
        trades = 0
        wins = 0
        
        while not train_env.stock.done:
            state = train_env.stock.get_state()
            action = agent.act(state)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å step
            next_state, trade_action, reward, done = train_env.step(action)
            
            agent.step(state, action, reward, next_state, done)
            
            total_reward += reward
            if trade_action != 0:  # –ï—Å–ª–∏ –±—ã–ª–∞ —Å–¥–µ–ª–∫–∞
                trades += 1
                if reward > 0:
                    wins += 1
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        metrics = train_env.get_trading_metrics()
        train_profit = metrics['total_profit_dollars']
        win_rate = metrics['win_rate'] * 100
        
        # OOS —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤
        if episode % 10 == 0:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ 5 —Ä–∞–∑–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏—è—Ö
            oos_profits = []
            for start_pos in range(0, min(50, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 10):
                oos_env.reset_fixed(start_pos)
                
                while not oos_env.stock.done:
                    state = oos_env.stock.get_state()
                    action = agent.act(state, training=False)  # –ë–ï–ó exploration
                    next_state, trade_action, reward, done = oos_env.step(action)
                
                oos_metrics = oos_env.get_trading_metrics()
                oos_profits.append(oos_metrics['total_profit_dollars'])
            
            median_oos = np.median(oos_profits)
            mean_oos = np.mean(oos_profits)
            consistency = (np.array(oos_profits) > 0).mean() * 100
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            if median_oos > 30:  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å
                stability_count += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            if median_oos > best_median:
                best_median = median_oos
                agent.save(f"models/{model_name}_best")
                print(f"üíæ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–µ–¥–∏–∞–Ω–∞: ${median_oos:.0f} (—ç–ø–∏–∑–æ–¥ {episode})")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            log_entry = (
                f"Ep: {episode:3d} | Train: ${train_profit:4.0f} | OOS Med: ${median_oos:4.0f}\n"
                f"    Train: {trades} trades, {win_rate:.1f}% win\n"
                f"    OOS: Med ${median_oos:.0f}, Mean ${mean_oos:.0f}, Consistency {consistency:.1f}%\n"
                f"    Epsilon: {agent.epsilon:.3f} | Best median: ${best_median:.0f}\n"
                f"    All OOS: {[int(p) for p in oos_profits]}\n"
                + "-" * 60
            )
            
            print(log_entry.replace("\n", "\n"))
            
            with open(log_file, "a", encoding='utf-8') as f:
                f.write(log_entry + "\n")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    agent.save(f"models/{model_name}")
    
    print(f"\nüß† LSTM –æ–±—É—á–µ–Ω–∏–µ v13 –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/{model_name}")
    print(f"üèÜ –õ—É—á—à–∞—è –º–µ–¥–∏–∞–Ω–∞: models/{model_name}_best")
    print(f"üìä –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_file}")
    print(f"üéØ –°—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {stability_count}/{config['episodes']//10}")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\nüî¨ –§–∏–Ω–∞–ª—å–Ω–æ–µ LSTM —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    final_profits = []
    for start_pos in range(0, min(100, len(oos_env.stock.closes) - config['trading_period'] - config['window']), 5):
        oos_env.reset_fixed(start_pos)
        
        while not oos_env.stock.done:
            state = oos_env.stock.get_state()
            action = agent.act(state, training=False)
            next_state, trade_action, reward, done = oos_env.step(action)
        
        oos_metrics = oos_env.get_trading_metrics()
        final_profits.append(oos_metrics['total_profit_dollars'])
    
    final_median = np.median(final_profits)
    final_consistency = (np.array(final_profits) > 0).mean() * 100
    final_std = np.std(final_profits)
    
    print(f"üìà –§–ò–ù–ê–õ–¨–ù–´–ï LSTM –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   –ú–µ–¥–∏–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏—Ç: ${final_median:.2f}")
    print(f"   Consistency: {final_consistency:.1f}%")
    print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: ${final_std:.2f}")
    print(f"   –î–∏–∞–ø–∞–∑–æ–Ω: ${min(final_profits):.0f} - ${max(final_profits):.0f}")
    
    if final_consistency > 60 and final_median > 100:
        print("‚úÖ LSTM –ø–æ–∫–∞–∑–∞–ª —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!")
    else:
        print("‚ùå LSTM —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏...")


if __name__ == "__main__":
    main() 